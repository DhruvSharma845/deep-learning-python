{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_bldr = tfds.builder('celeb_a')\n",
    "celeba_bldr.download_and_prepare()\n",
    "celeba_ds = celeba_bldr.as_dataset(shuffle_files=False)\n",
    "celeba_train = celeba_ds['train']\n",
    "celeba_val = celeba_ds['validation']\n",
    "celeba_test = celeba_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_train = celeba_train.take(16000)\n",
    "celeba_val = celeba_val.take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_augmentation(example, size=(64, 64), mode='train'):\n",
    "    image = example['image']\n",
    "    label = example['attributes']['Male']\n",
    "\n",
    "    if mode == 'train':\n",
    "        image_cropped = tf.image.random_crop(image, size=(178, 178, 3))\n",
    "        image_resized = tf.image.resize(image_cropped, size=size)\n",
    "        image_flipped = tf.image.random_flip_left_right(image_resized)\n",
    "        return image_flipped/255.0, tf.cast(label, tf.int32) \n",
    "    else:\n",
    "        image_cropped = tf.image.crop_to_bounding_box(image, offset_height=20, offset_width=0, target_height=178, target_width=178)\n",
    "        image_resized = tf.image.resize(image_cropped,size=size)\n",
    "        return image_resized/255.0, tf.cast(label, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(218, 178, 3), dtype=uint8, numpy=\n",
       "array([[[ 30,  32,  21],\n",
       "        [ 30,  32,  21],\n",
       "        [ 31,  33,  22],\n",
       "        ...,\n",
       "        [ 19,  19,  17],\n",
       "        [ 10,  10,   8],\n",
       "        [ 10,  11,   6]],\n",
       "\n",
       "       [[ 17,  19,   8],\n",
       "        [ 18,  20,   9],\n",
       "        [ 19,  21,  10],\n",
       "        ...,\n",
       "        [ 22,  22,  20],\n",
       "        [ 15,  15,  13],\n",
       "        [ 15,  16,  11]],\n",
       "\n",
       "       [[  5,   6,   0],\n",
       "        [  6,   7,   0],\n",
       "        [  7,   8,   0],\n",
       "        ...,\n",
       "        [ 27,  27,  25],\n",
       "        [ 22,  22,  20],\n",
       "        [ 22,  23,  18]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[107,  92,  89],\n",
       "        [ 73,  58,  55],\n",
       "        [ 55,  37,  33],\n",
       "        ...,\n",
       "        [ 40,  36,  25],\n",
       "        [ 63,  59,  48],\n",
       "        [ 65,  61,  50]],\n",
       "\n",
       "       [[106,  91,  88],\n",
       "        [ 72,  57,  54],\n",
       "        [ 50,  32,  28],\n",
       "        ...,\n",
       "        [ 54,  48,  36],\n",
       "        [ 73,  69,  58],\n",
       "        [ 73,  69,  58]],\n",
       "\n",
       "       [[113,  98,  95],\n",
       "        [ 78,  63,  60],\n",
       "        [ 55,  37,  33],\n",
       "        ...,\n",
       "        [ 54,  48,  36],\n",
       "        [ 75,  68,  58],\n",
       "        [ 73,  69,  58]]], dtype=uint8)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "next(iter(celeba_train))['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "IMAGE_SIZE=(150,150)\n",
    "celeba_train = celeba_train.map(lambda x: preprocess_augmentation(x, size=IMAGE_SIZE, mode='train'))\n",
    "celeba_train = celeba_train.shuffle(buffer_size=2000).repeat().batch(32)\n",
    "\n",
    "celeba_val = celeba_val.map(lambda x: preprocess_augmentation(x, size=IMAGE_SIZE, mode='eval'))\n",
    "celeba_val = celeba_val.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 150, 150, 3), dtype=float32, numpy=\n",
       "array([[[[0.37328106, 0.24779086, 0.3928889 ],\n",
       "         [0.3814902 , 0.25599998, 0.40109804],\n",
       "         [0.38248366, 0.25699347, 0.4020915 ],\n",
       "         ...,\n",
       "         [0.39607844, 0.2784314 , 0.41960785],\n",
       "         [0.3989019 , 0.28125486, 0.42807826],\n",
       "         [0.4       , 0.28235295, 0.43137255]],\n",
       "\n",
       "        [[0.37328106, 0.24779086, 0.3928889 ],\n",
       "         [0.3814902 , 0.25599998, 0.40109804],\n",
       "         [0.38248366, 0.25699347, 0.4020915 ],\n",
       "         ...,\n",
       "         [0.39607844, 0.2784314 , 0.41960785],\n",
       "         [0.3989019 , 0.28125486, 0.42807826],\n",
       "         [0.4       , 0.28235295, 0.43137255]],\n",
       "\n",
       "        [[0.37328106, 0.24779086, 0.3928889 ],\n",
       "         [0.3814902 , 0.25599998, 0.40109804],\n",
       "         [0.38248366, 0.25699347, 0.4020915 ],\n",
       "         ...,\n",
       "         [0.39607844, 0.2784314 , 0.41960785],\n",
       "         [0.3989019 , 0.28125486, 0.42807826],\n",
       "         [0.4       , 0.28235295, 0.43137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6784314 , 0.6745098 , 0.65882355],\n",
       "         [0.6784314 , 0.6745098 , 0.65882355],\n",
       "         [0.6784314 , 0.6745098 , 0.65882355],\n",
       "         ...,\n",
       "         [0.6529333 , 0.5284191 , 0.4274518 ],\n",
       "         [0.6769352 , 0.5542685 , 0.44775885],\n",
       "         [0.7041043 , 0.5825357 , 0.46917623]],\n",
       "\n",
       "        [[0.67304796, 0.6691264 , 0.6534401 ],\n",
       "         [0.6756079 , 0.67168635, 0.6560001 ],\n",
       "         [0.6756079 , 0.67168635, 0.6560001 ],\n",
       "         ...,\n",
       "         [0.66519153, 0.54153144, 0.43800196],\n",
       "         [0.7217672 , 0.5991005 , 0.4925908 ],\n",
       "         [0.77639604, 0.6548274 , 0.54146796]],\n",
       "\n",
       "        [[0.6709543 , 0.6670327 , 0.65134645],\n",
       "         [0.6745098 , 0.67058825, 0.654902  ],\n",
       "         [0.6745098 , 0.67058825, 0.654902  ],\n",
       "         ...,\n",
       "         [0.64583504, 0.5240713 , 0.41485298],\n",
       "         [0.70624155, 0.5845704 , 0.47507396],\n",
       "         [0.7671975 , 0.64562887, 0.5322694 ]]],\n",
       "\n",
       "\n",
       "       [[[0.24885473, 0.1390508 , 0.0527763 ],\n",
       "         [0.26327425, 0.15347032, 0.06719581],\n",
       "         [0.27011764, 0.16031371, 0.07403922],\n",
       "         ...,\n",
       "         [0.6787974 , 0.60036606, 0.36149192],\n",
       "         [0.6816209 , 0.6031895 , 0.3588539 ],\n",
       "         [0.682719  , 0.6075113 , 0.35084972]],\n",
       "\n",
       "        [[0.2555315 , 0.14572759, 0.05945307],\n",
       "         [0.26243764, 0.15263373, 0.06635921],\n",
       "         [0.26081046, 0.15100652, 0.06473203],\n",
       "         ...,\n",
       "         [0.6812549 , 0.60282356, 0.36843926],\n",
       "         [0.6840784 , 0.605647  , 0.3686274 ],\n",
       "         [0.6851765 , 0.6067451 , 0.36261442]],\n",
       "\n",
       "        [[0.25492638, 0.14512244, 0.05884793],\n",
       "         [0.2551634 , 0.14535947, 0.05908497],\n",
       "         [0.25150326, 0.14169934, 0.05542484],\n",
       "         ...,\n",
       "         [0.67660135, 0.59817   , 0.3667974 ],\n",
       "         [0.6794248 , 0.60099345, 0.36962086],\n",
       "         [0.6805229 , 0.60209155, 0.3669264 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0580286 , 0.05410704, 0.07763645],\n",
       "         [0.06190843, 0.05798687, 0.08151627],\n",
       "         [0.05652277, 0.0526012 , 0.07613061],\n",
       "         ...,\n",
       "         [0.7155556 , 0.6426145 , 0.4407844 ],\n",
       "         [0.7116027 , 0.63866156, 0.43683147],\n",
       "         [0.7100653 , 0.63712424, 0.43529412]],\n",
       "\n",
       "        [[0.06101972, 0.05709815, 0.08062756],\n",
       "         [0.06071225, 0.05679068, 0.0803201 ],\n",
       "         [0.05992162, 0.05600005, 0.07952946],\n",
       "         ...,\n",
       "         [0.71090204, 0.63247067, 0.43247065],\n",
       "         [0.71090204, 0.63247067, 0.43247065],\n",
       "         [0.71090204, 0.63247067, 0.43247065]],\n",
       "\n",
       "        [[0.05171245, 0.04779088, 0.0713203 ],\n",
       "         [0.05171245, 0.04779088, 0.0713203 ],\n",
       "         [0.05337171, 0.04945014, 0.07297955],\n",
       "         ...,\n",
       "         [0.70980394, 0.6313726 , 0.42426148],\n",
       "         [0.70980394, 0.6313726 , 0.42426148],\n",
       "         [0.70980394, 0.6313726 , 0.42426148]]],\n",
       "\n",
       "\n",
       "       [[[0.16151635, 0.11053595, 0.07879739],\n",
       "         [0.16261443, 0.11163404, 0.07989548],\n",
       "         [0.16543792, 0.11445752, 0.08271896],\n",
       "         ...,\n",
       "         [0.12732026, 0.07633987, 0.04104575],\n",
       "         [0.12266667, 0.07450981, 0.0307451 ],\n",
       "         [0.09634789, 0.04928906, 0.00256209]],\n",
       "\n",
       "        [[0.1730196 , 0.12203921, 0.08674509],\n",
       "         [0.17288785, 0.12190745, 0.08661333],\n",
       "         [0.17254902, 0.12156863, 0.08627451],\n",
       "         ...,\n",
       "         [0.12732026, 0.07633987, 0.04104575],\n",
       "         [0.12266667, 0.07450981, 0.0307451 ],\n",
       "         [0.09312418, 0.04606536, 0.00256209]],\n",
       "\n",
       "        [[0.18431373, 0.1351634 , 0.09437909],\n",
       "         [0.18358167, 0.13443133, 0.09364703],\n",
       "         [0.18169934, 0.13254902, 0.0917647 ],\n",
       "         ...,\n",
       "         [0.12793028, 0.07694989, 0.04165577],\n",
       "         [0.11373595, 0.06557909, 0.02181438],\n",
       "         [0.09375861, 0.04669978, 0.00153725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21751638, 0.1508497 , 0.08810461],\n",
       "         [0.21700391, 0.15033725, 0.08759215],\n",
       "         [0.21568628, 0.14901961, 0.08627451],\n",
       "         ...,\n",
       "         [0.24718077, 0.20404352, 0.18835725],\n",
       "         [0.24936993, 0.20623268, 0.19054641],\n",
       "         [0.26164708, 0.21850981, 0.20282353]],\n",
       "\n",
       "        [[0.2128628 , 0.14619613, 0.08345103],\n",
       "         [0.2128628 , 0.14619613, 0.08345103],\n",
       "         [0.2128628 , 0.14619613, 0.08345103],\n",
       "         ...,\n",
       "         [0.2550483 , 0.21191102, 0.19622475],\n",
       "         [0.25349638, 0.21035914, 0.19467287],\n",
       "         [0.25935066, 0.21621338, 0.2005271 ]],\n",
       "\n",
       "        [[0.21532024, 0.14865358, 0.08590848],\n",
       "         [0.21631585, 0.14964919, 0.08690408],\n",
       "         [0.21887578, 0.15220912, 0.08946402],\n",
       "         ...,\n",
       "         [0.26052457, 0.21738735, 0.20170107],\n",
       "         [0.25945303, 0.21631579, 0.20062952],\n",
       "         [0.25234202, 0.20920475, 0.19351847]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.32168087, 0.4036678 , 0.5231086 ],\n",
       "         [0.6753778 , 0.74722093, 0.85200524],\n",
       "         [0.8017708 , 0.84569234, 0.93850285],\n",
       "         ...,\n",
       "         [0.5439093 , 0.29571068, 0.2906005 ],\n",
       "         [0.5440482 , 0.30137503, 0.2775866 ],\n",
       "         [0.5391895 , 0.30771238, 0.26677126]],\n",
       "\n",
       "        [[0.2987587 , 0.38074562, 0.49573016],\n",
       "         [0.6892423 , 0.76108545, 0.8658698 ],\n",
       "         [0.82031894, 0.8657778 , 0.95910066],\n",
       "         ...,\n",
       "         [0.61208886, 0.33150324, 0.33904317],\n",
       "         [0.60517037, 0.32610524, 0.3171706 ],\n",
       "         [0.59801304, 0.32684967, 0.30206537]],\n",
       "\n",
       "        [[0.3143878 , 0.39986405, 0.5223111 ],\n",
       "         [0.6957072 , 0.7693804 , 0.8809725 ],\n",
       "         [0.80815685, 0.8593987 , 0.95867544],\n",
       "         ...,\n",
       "         [0.6046536 , 0.30576035, 0.3277909 ],\n",
       "         [0.60763395, 0.3090823 , 0.3171348 ],\n",
       "         [0.60646975, 0.3122231 , 0.30687585]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.08547631, 0.10508415, 0.08155474],\n",
       "         [0.07916342, 0.09767324, 0.07963402],\n",
       "         [0.0763399 , 0.09202617, 0.08810461],\n",
       "         ...,\n",
       "         [0.16116814, 0.16998732, 0.21509407],\n",
       "         [0.15413402, 0.16380726, 0.20537579],\n",
       "         [0.15215753, 0.16183077, 0.20008074]],\n",
       "\n",
       "        [[0.0735165 , 0.09312434, 0.06959493],\n",
       "         [0.07044405, 0.08895386, 0.07091465],\n",
       "         [0.0756392 , 0.09132547, 0.0874039 ],\n",
       "         ...,\n",
       "         [0.22298405, 0.23082718, 0.28686887],\n",
       "         [0.23144549, 0.23928863, 0.29481786],\n",
       "         [0.23513488, 0.24297802, 0.29338738]],\n",
       "\n",
       "        [[0.063443  , 0.08305085, 0.05952143],\n",
       "         [0.06620027, 0.08471007, 0.06667086],\n",
       "         [0.08129321, 0.09697948, 0.09305792],\n",
       "         ...,\n",
       "         [0.20867997, 0.21296757, 0.2824577 ],\n",
       "         [0.21052474, 0.21481234, 0.28430247],\n",
       "         [0.2112422 , 0.21875347, 0.27790886]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.16679735, 0.16679735, 0.17464049],\n",
       "         [0.16397388, 0.16397388, 0.17181702],\n",
       "         [0.16287579, 0.16287579, 0.17071892]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.16862746, 0.16862746, 0.1764706 ],\n",
       "         [0.16986969, 0.16986969, 0.17771283],\n",
       "         [0.17035283, 0.17035283, 0.17819597]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.16862746, 0.16862746, 0.1764706 ],\n",
       "         [0.17401086, 0.17401086, 0.181854  ],\n",
       "         [0.17610456, 0.17610456, 0.1839477 ]]],\n",
       "\n",
       "\n",
       "       [[[0.06593464, 0.06593464, 0.06593464],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         ...,\n",
       "         [0.24679744, 0.250719  , 0.2271896 ],\n",
       "         [0.2516077 , 0.24423535, 0.21788247],\n",
       "         [0.25490198, 0.24313726, 0.21568628]],\n",
       "\n",
       "        [[0.06593464, 0.06593464, 0.06593464],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         ...,\n",
       "         [0.24679744, 0.250719  , 0.2271896 ],\n",
       "         [0.2516077 , 0.24423535, 0.21788247],\n",
       "         [0.25490198, 0.24313726, 0.21568628]],\n",
       "\n",
       "        [[0.06593464, 0.06593464, 0.06593464],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         ...,\n",
       "         [0.24679744, 0.250719  , 0.2271896 ],\n",
       "         [0.25292528, 0.24555297, 0.21920009],\n",
       "         [0.25673202, 0.24496733, 0.21751635]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.05490196, 0.05098039, 0.07450981],\n",
       "         [0.05490196, 0.05098039, 0.07450981],\n",
       "         [0.05490196, 0.05098039, 0.07450981],\n",
       "         ...,\n",
       "         [0.91764706, 0.9529412 , 0.98039216],\n",
       "         [0.9191529 , 0.95444703, 0.97625107],\n",
       "         [0.91973853, 0.95503265, 0.9746405 ]],\n",
       "\n",
       "        [[0.05490196, 0.05098039, 0.07450981],\n",
       "         [0.05490196, 0.05098039, 0.07450981],\n",
       "         [0.05490196, 0.05098039, 0.07450981],\n",
       "         ...,\n",
       "         [0.9189647 , 0.9542588 , 0.9817098 ],\n",
       "         [0.92047054, 0.95576465, 0.9775687 ],\n",
       "         [0.92156863, 0.95686275, 0.9764706 ]],\n",
       "\n",
       "        [[0.05490196, 0.05098039, 0.07450981],\n",
       "         [0.05490196, 0.05098039, 0.07450981],\n",
       "         [0.05490196, 0.05098039, 0.07450981],\n",
       "         ...,\n",
       "         [0.9213734 , 0.95666754, 0.9841185 ],\n",
       "         [0.9240261 , 0.95420027, 0.97856426],\n",
       "         [0.92512417, 0.9533072 , 0.9764706 ]]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "next(iter(celeba_train))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Functional)           (None, 4, 4, 512)         14714688  \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               2097408   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 16,812,353\nTrainable params: 16,812,353\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "network = tf.keras.models.Sequential([\n",
    "    conv_base,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 553s 1s/step - loss: 0.4222 - accuracy: 0.8095 - val_loss: 0.2402 - val_accuracy: 0.9070\n",
      "Epoch 2/10\n",
      "  8/500 [..............................] - ETA: 8:50 - loss: 0.3095 - accuracy: 0.8902"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8ddf1e6d36fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mceleba_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mceleba_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dhrsharm\\Documents\\ml_dl\\hands_on_machine_learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-5), metrics=['accuracy'])\n",
    "history = network.fit(celeba_train, epochs=10, validation_data=celeba_val, steps_per_epoch=np.ceil(16000/32))\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}